"""
Sibang OCR ì—”ì§„ ê°œë°œ ê°€ì´ë“œ
ì „í†µì‹œì¥ íŠ¹í™” OCR ì—”ì§„ ê°œë°œì„ ìœ„í•œ ë‹¨ê³„ë³„ êµ¬í˜„ ê³„íš
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pytesseract
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import json
import re
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv

class SibangOCREngine:
    """
    Sibang OCR ì—”ì§„ - ì „í†µì‹œì¥ íŠ¹í™” OCR
    
    ê°œë°œ ë‹¨ê³„:
    1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
    2. ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„
    3. í•™ìŠµ ë° ê²€ì¦
    4. ë°°í¬ ë° ìµœì í™”
    """
    
    def __init__(self):
        """Sibang OCR ì—”ì§„ ì´ˆê¸°í™”"""
        load_dotenv("sibangaiocr.env")
        self.is_available = False
        self.version = "0.1.0-dev"
        
        # ëª¨ë¸ ê´€ë ¨ ì†ì„±ë“¤
        self.model = None
        self.processor = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ì „í†µì‹œì¥ íŠ¹í™” ì„¤ì •
        self.market_keywords = self._load_market_keywords()
        self.price_patterns = self._load_price_patterns()
        
    def _load_market_keywords(self) -> List[str]:
        """ì „í†µì‹œì¥ íŠ¹í™” í‚¤ì›Œë“œ ë¡œë“œ"""
        return [
            # ê³¼ì¼ë¥˜
            "ì‚¬ê³¼", "ë°°", "í¬ë„", "ë”¸ê¸°", "ë°”ë‚˜ë‚˜", "ì˜¤ë Œì§€", "ê·¤", "ë ˆëª¬", "ë³µìˆ­ì•„", "ìë‘",
            "ìˆ˜ë°•", "ì°¸ì™¸", "ë©œë¡ ", "í‚¤ìœ„", "íŒŒì¸ì• í”Œ", "ë§ê³ ", "ì²´ë¦¬", "ì‚´êµ¬", "ê°", "ëŒ€ì¶”",
            
            # ì±„ì†Œë¥˜
            "ë°°ì¶”", "ë¬´", "ë‹¹ê·¼", "ì–‘íŒŒ", "ë§ˆëŠ˜", "ìƒê°•", "ê³ ì¶”", "í”¼ë§", "í† ë§ˆí† ", "ì˜¤ì´",
            "ê°€ì§€", "í˜¸ë°•", "ì‹œê¸ˆì¹˜", "ìƒì¶”", "ê¹»ì", "ë¯¸ë‚˜ë¦¬", "ì‘¥ê°“", "ë¶€ì¶”", "íŒŒ", "ëŒ€íŒŒ",
            
            # ê³¡ë¬¼ë¥˜
            "ìŒ€", "ë³´ë¦¬", "ë°€", "ì˜¥ìˆ˜ìˆ˜", "ì½©", "íŒ¥", "ë…¹ë‘", "ì°¸ê¹¨", "ë“¤ê¹¨", "ë•…ì½©",
            
            # í•´ì‚°ë¬¼
            "ìƒì„ ", "ê³ ë“±ì–´", "ì‚¼ì¹˜", "ê½ì¹˜", "ë©¸ì¹˜", "ìƒˆìš°", "ê²Œ", "ë¬¸ì–´", "ì˜¤ì§•ì–´", "ë‚™ì§€",
            "ì „ë³µ", "ì†Œë¼", "í™í•©", "êµ´", "ë°”ì§€ë½", "ì¡°ê°œ", "í•´ì‚¼", "ë©ê²Œ", "ì„±ê²Œ",
            
            # ìœ¡ë¥˜
            "ì†Œê³ ê¸°", "ë¼ì§€ê³ ê¸°", "ë‹­ê³ ê¸°", "ì˜¤ë¦¬ê³ ê¸°", "ì–‘ê³ ê¸°", "í–„", "ì†Œì‹œì§€", "ë² ì´ì»¨",
            
            # ê¸°íƒ€ ì‹í’ˆ
            "ë‘ë¶€", "ìˆœë‘ë¶€", "ì½©ë‚˜ë¬¼", "ìˆ™ì£¼", "ë²„ì„¯", "í‘œê³ ë²„ì„¯", "íŒ½ì´ë²„ì„¯", "ëŠíƒ€ë¦¬ë²„ì„¯",
            
            # ë‹¨ìœ„ ë° ê°€ê²© ê´€ë ¨
            "ì›", "ê°œ", "ë´‰", "í¬ê¸°", "ë‹¨", "kg", "g", "ê·¼", "ë§", "ë˜", "ê°€ë§ˆ",
            "í• ì¸", "íŠ¹ê°€", "ì„¸ì¼", "ë¬´ë£Œ", "ê³µì§œ", "ì¦ì •", "ì‚¬ì€í’ˆ"
        ]
    
    def _load_price_patterns(self) -> List[str]:
        """ê°€ê²© íŒ¨í„´ ë¡œë“œ"""
        return [
            r'\d{1,3}(?:,\d{3})*\s*ì›',  # 1,000ì›, 500ì› ë“±
            r'\d+\s*ì›',                  # 1000ì›, 500ì› ë“±
            r'\d{1,2}\s*ë§Œ\s*ì›',         # 1ë§Œì›, 5ë§Œì› ë“±
            r'\d+\s*ì²œ\s*ì›',             # 1000ì›, 5000ì› ë“±
            r'\d+\s*/\s*kg',              # 1000/kg ë“±
            r'\d+\s*/\s*ê°œ',              # 1000/ê°œ ë“±
        ]

class SibangDataset(Dataset):
    """
    Sibang OCRìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤
    ì „í†µì‹œì¥ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ìŒì„ ê´€ë¦¬
    """
    
    def __init__(self, image_paths: List[str], labels: List[str], transform=None):
        """
        ë°ì´í„°ì…‹ ì´ˆê¸°í™”
        
        Args:
            image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            labels: í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
            transform: ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜
        """
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            image = self.transform(image)
        
        # ë¼ë²¨
        label = self.labels[idx]
        
        return image, label

class SibangOCRProcessor:
    """
    Sibang OCR í”„ë¡œì„¸ì„œ - ì‹¤ì œ êµ¬í˜„
    """
    
    def __init__(self):
        self.engine = SibangOCREngine()
        self._initialize_models()
    
    def _initialize_models(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # TrOCR ëª¨ë¸ ë¡œë“œ (Microsoftì˜ Vision-Language ëª¨ë¸)
            model_name = "microsoft/trocr-base-printed"
            self.processor = TrOCRProcessor.from_pretrained(model_name)
            self.model = VisionEncoderDecoderModel.from_pretrained(model_name)
            self.model.to(self.engine.device)
            
            print("âœ… TrOCR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.processor = None
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - ì „í†µì‹œì¥ íŠ¹í™”
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì—´
        """
        # ì´ë¯¸ì§€ ì½ê¸°
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # 2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
        denoised = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # 3. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # 4. ì ì‘ì  ì„ê³„ê°’ ì²˜ë¦¬
        binary = cv2.adaptiveThreshold(
            enhanced, 255, 
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        # 5. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((2, 2), np.uint8)
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # 6. í…ìŠ¤íŠ¸ ì˜ì—­ ê°•ì¡°
        # í…ìŠ¤íŠ¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì–´ë‘ìš´ ìƒ‰ì´ë¯€ë¡œ ë°˜ì „
        inverted = cv2.bitwise_not(cleaned)
        
        return inverted
    
    def extract_text_regions(self, image: np.ndarray) -> List[np.ndarray]:
        """
        í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ
        
        Args:
            image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
            
        Returns:
            í…ìŠ¤íŠ¸ ì˜ì—­ ë¦¬ìŠ¤íŠ¸
        """
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        
        for contour in contours:
            # ê²½ê³„ ìƒì ê³„ì‚°
            x, y, w, h = cv2.boundingRect(contour)
            
            # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
            if w < 20 or h < 10:
                continue
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ
            text_region = image[y:y+h, x:x+w]
            text_regions.append(text_region)
        
        return text_regions
    
    def recognize_with_trocr(self, image: np.ndarray) -> str:
        """
        TrOCRì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¸ì‹
        
        Args:
            image: ì´ë¯¸ì§€ ë°°ì—´
            
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸
        """
        if self.model is None or self.processor is None:
            return ""
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # TrOCR ì²˜ë¦¬
            pixel_values = self.processor(pil_image, return_tensors="pt").pixel_values
            pixel_values = pixel_values.to(self.engine.device)
            
            # í…ìŠ¤íŠ¸ ìƒì„±
            generated_ids = self.model.generate(pixel_values)
            generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
            
            return generated_text.strip()
            
        except Exception as e:
            print(f"TrOCR ì¸ì‹ ì˜¤ë¥˜: {e}")
            return ""
    
    def recognize_with_tesseract(self, image: np.ndarray) -> str:
        """
        Tesseractë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¸ì‹ (ë°±ì—…)
        
        Args:
            image: ì´ë¯¸ì§€ ë°°ì—´
            
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸
        """
        try:
            # PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # Tesseract ì„¤ì • (í•œêµ­ì–´ ìµœì í™”)
            config = r'--oem 3 --psm 6 -l kor+eng'
            text = pytesseract.image_to_string(pil_image, config=config)
            
            return text.strip()
            
        except Exception as e:
            print(f"Tesseract ì¸ì‹ ì˜¤ë¥˜: {e}")
            return ""
    
    def post_process_text(self, text: str) -> Dict[str, str]:
        """
        í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ - ì „í†µì‹œì¥ íŠ¹í™”
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì¡°í™”ëœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            "raw_text": text,
            "product_name": "",
            "price": "",
            "unit": "",
            "additional_info": ""
        }
        
        # ê°€ê²© íŒ¨í„´ ë§¤ì¹­
        for pattern in self.engine.price_patterns:
            price_match = re.search(pattern, text)
            if price_match:
                result["price"] = price_match.group(0)
                break
        
        # ìƒí’ˆëª… ì¶”ì¶œ (ê°€ê²© ì•ë¶€ë¶„)
        if result["price"]:
            price_start = text.find(result["price"])
            product_part = text[:price_start].strip()
            result["product_name"] = product_part
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ìƒí’ˆëª… ë³´ì™„
        for keyword in self.engine.market_keywords:
            if keyword in text and not result["product_name"]:
                result["product_name"] = keyword
                break
        
        # ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ
        unit_patterns = [r'(\d+)\s*ê°œ', r'(\d+)\s*kg', r'(\d+)\s*ê·¼', r'(\d+)\s*ë´‰']
        for pattern in unit_patterns:
            unit_match = re.search(pattern, text)
            if unit_match:
                result["unit"] = unit_match.group(0)
                break
        
        return result
    
    def process_image(self, image_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self.preprocess_image(image_path)
            
            # 2. í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ
            text_regions = self.extract_text_regions(processed_image)
            
            # 3. ê° ì˜ì—­ë³„ í…ìŠ¤íŠ¸ ì¸ì‹
            all_texts = []
            for region in text_regions:
                # TrOCR ì‹œë„
                trocr_text = self.recognize_with_trocr(region)
                if trocr_text:
                    all_texts.append(trocr_text)
                else:
                    # Tesseract ë°±ì—…
                    tesseract_text = self.recognize_with_tesseract(region)
                    if tesseract_text:
                        all_texts.append(tesseract_text)
            
            # 4. ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
            full_text = " ".join(all_texts)
            
            # 5. í›„ì²˜ë¦¬
            structured_result = self.post_process_text(full_text)
            
            return {
                "success": True,
                "engine": "Sibang OCR",
                "text": full_text,
                "structured": structured_result,
                "regions_count": len(text_regions)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "engine": "Sibang OCR"
            }

# ë°ì´í„° ìˆ˜ì§‘ ë° í•™ìŠµì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
class SibangDataCollector:
    """
    Sibang OCRìš© ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬
    """
    
    def __init__(self):
        self.collected_data = []
    
    def collect_from_web(self, search_terms: List[str], max_images: int = 100):
        """
        ì›¹ì—ì„œ ì „í†µì‹œì¥ ì´ë¯¸ì§€ ìˆ˜ì§‘
        
        Args:
            search_terms: ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
            max_images: ìµœëŒ€ ìˆ˜ì§‘ ì´ë¯¸ì§€ ìˆ˜
        """
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Selenium, BeautifulSoup ë“±ì„ ì‚¬ìš©
        print(f"ğŸ” ì›¹ì—ì„œ ì „í†µì‹œì¥ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘... (ìµœëŒ€ {max_images}ê°œ)")
        print(f"ê²€ìƒ‰ì–´: {', '.join(search_terms)}")
        
        # TODO: ì‹¤ì œ ì›¹ ìŠ¤í¬ë˜í•‘ êµ¬í˜„
        pass
    
    def create_synthetic_data(self, base_images: List[str], text_overlays: List[str]):
        """
        í•©ì„± ë°ì´í„° ìƒì„±
        
        Args:
            base_images: ê¸°ë³¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            text_overlays: ì˜¤ë²„ë ˆì´í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ¨ í•©ì„± ë°ì´í„° ìƒì„± ì¤‘...")
        
        # TODO: ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ êµ¬í˜„
        pass
    
    def validate_data(self, image_path: str, expected_text: str) -> bool:
        """
        ë°ì´í„° ê²€ì¦
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            expected_text: ì˜ˆìƒ í…ìŠ¤íŠ¸
            
        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        # TODO: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ êµ¬í˜„
        return True

# í•™ìŠµì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
class SibangTrainer:
    """
    Sibang OCR ëª¨ë¸ í•™ìŠµ ë„êµ¬
    """
    
    def __init__(self):
        self.model = None
        self.optimizer = None
        self.criterion = None
    
    def prepare_dataset(self, data_dir: str) -> Tuple[DataLoader, DataLoader]:
        """
        ë°ì´í„°ì…‹ ì¤€ë¹„
        
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            
        Returns:
            í•™ìŠµìš©, ê²€ì¦ìš© DataLoader
        """
        # TODO: ë°ì´í„°ì…‹ ë¡œë” êµ¬í˜„
        pass
    
    def train_model(self, train_loader: DataLoader, val_loader: DataLoader, epochs: int = 10):
        """
        ëª¨ë¸ í•™ìŠµ
        
        Args:
            train_loader: í•™ìŠµìš© ë°ì´í„° ë¡œë”
            val_loader: ê²€ì¦ìš© ë°ì´í„° ë¡œë”
            epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
        """
        print(f"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ì—í¬í¬: {epochs})")
        
        # TODO: ì‹¤ì œ í•™ìŠµ ë£¨í”„ êµ¬í˜„
        pass
    
    def save_model(self, model_path: str):
        """
        ëª¨ë¸ ì €ì¥
        
        Args:
            model_path: ì €ì¥í•  ëª¨ë¸ ê²½ë¡œ
        """
        # TODO: ëª¨ë¸ ì €ì¥ êµ¬í˜„
        pass

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # Sibang OCR í”„ë¡œì„¸ì„œ ìƒì„±
    processor = SibangOCRProcessor()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬
    test_image = "sample_images/test_market.jpg"
    if os.path.exists(test_image):
        result = processor.process_image(test_image)
        print("ğŸ“Š Sibang OCR ê²°ê³¼:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ sample_images/test_market.jpg íŒŒì¼ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")










