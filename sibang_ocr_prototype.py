"""
Sibang OCR í”„ë¡œí† íƒ€ì… - ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ë²„ì „
TrOCR ê¸°ë°˜ ì „í†µì‹œì¥ íŠ¹í™” OCR ì—”ì§„
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import json
import re
from typing import Dict, List, Optional
from dotenv import load_dotenv

class SibangOCRPrototype:
    """
    Sibang OCR í”„ë¡œí† íƒ€ì…
    TrOCR ê¸°ë°˜ ì „í†µì‹œì¥ íŠ¹í™” OCR ì—”ì§„
    """
    
    def __init__(self):
        """í”„ë¡œí† íƒ€ì… ì´ˆê¸°í™”"""
        load_dotenv("sibangaiocr.env")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.processor = None
        
        # ì „í†µì‹œì¥ íŠ¹í™” ì„¤ì •
        self.market_keywords = self._load_market_keywords()
        self.price_patterns = self._load_price_patterns()
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
    
    def _load_market_keywords(self) -> List[str]:
        """ì „í†µì‹œì¥ íŠ¹í™” í‚¤ì›Œë“œ ë¡œë“œ"""
        return [
            # ê³¼ì¼ë¥˜
            "ì‚¬ê³¼", "ë°°", "í¬ë„", "ë”¸ê¸°", "ë°”ë‚˜ë‚˜", "ì˜¤ë Œì§€", "ê·¤", "ë ˆëª¬", "ë³µìˆ­ì•„", "ìë‘",
            "ìˆ˜ë°•", "ì°¸ì™¸", "ë©œë¡ ", "í‚¤ìœ„", "íŒŒì¸ì• í”Œ", "ë§ê³ ", "ì²´ë¦¬", "ì‚´êµ¬", "ê°", "ëŒ€ì¶”",
            "í•˜ìš°ìŠ¤ê·¤", "ì†¡ì´í¬ë„", "ë¬´ë†ì•½", "ìœ ê¸°ë†",
            
            # ì±„ì†Œë¥˜
            "ë°°ì¶”", "ë¬´", "ë‹¹ê·¼", "ì–‘íŒŒ", "ë§ˆëŠ˜", "ìƒê°•", "ê³ ì¶”", "í”¼ë§", "í† ë§ˆí† ", "ì˜¤ì´",
            "ê°€ì§€", "í˜¸ë°•", "ì‹œê¸ˆì¹˜", "ìƒì¶”", "ê¹»ì", "ë¯¸ë‚˜ë¦¬", "ì‘¥ê°“", "ë¶€ì¶”", "íŒŒ", "ëŒ€íŒŒ",
            
            # ê³¡ë¬¼ë¥˜
            "ìŒ€", "ë³´ë¦¬", "ë°€", "ì˜¥ìˆ˜ìˆ˜", "ì½©", "íŒ¥", "ë…¹ë‘", "ì°¸ê¹¨", "ë“¤ê¹¨", "ë•…ì½©",
            
            # í•´ì‚°ë¬¼
            "ìƒì„ ", "ê³ ë“±ì–´", "ì‚¼ì¹˜", "ê½ì¹˜", "ë©¸ì¹˜", "ìƒˆìš°", "ê²Œ", "ë¬¸ì–´", "ì˜¤ì§•ì–´", "ë‚™ì§€",
            "ì „ë³µ", "ì†Œë¼", "í™í•©", "êµ´", "ë°”ì§€ë½", "ì¡°ê°œ", "í•´ì‚¼", "ë©ê²Œ", "ì„±ê²Œ",
            
            # ìœ¡ë¥˜
            "ì†Œê³ ê¸°", "ë¼ì§€ê³ ê¸°", "ë‹­ê³ ê¸°", "ì˜¤ë¦¬ê³ ê¸°", "ì–‘ê³ ê¸°", "í–„", "ì†Œì‹œì§€", "ë² ì´ì»¨",
            
            # ê¸°íƒ€ ì‹í’ˆ
            "ë‘ë¶€", "ìˆœë‘ë¶€", "ì½©ë‚˜ë¬¼", "ìˆ™ì£¼", "ë²„ì„¯", "í‘œê³ ë²„ì„¯", "íŒ½ì´ë²„ì„¯", "ëŠíƒ€ë¦¬ë²„ì„¯",
            
            # íŠ¹ìˆ˜ ìƒí’ˆ
            "ì˜»ë‚˜ë¬´", "êµ­ì‚°", "ì œì£¼", "ê³ ì²™ê·¼ë¦°ì‹œì¥",
            
            # ë‹¨ìœ„ ë° ê°€ê²© ê´€ë ¨
            "ì›", "ê°œ", "ë´‰", "í¬ê¸°", "ë‹¨", "kg", "g", "ê·¼", "ë§", "ë˜", "ê°€ë§ˆ",
            "í• ì¸", "íŠ¹ê°€", "ì„¸ì¼", "ë¬´ë£Œ", "ê³µì§œ", "ì¦ì •", "ì‚¬ì€í’ˆ"
        ]
    
    def _load_price_patterns(self) -> List[str]:
        """ê°€ê²© íŒ¨í„´ ë¡œë“œ"""
        return [
            r'\d{1,3}(?:,\d{3})*\s*ì›',  # 1,000ì›, 500ì› ë“±
            r'\d+\s*ì›',                  # 1000ì›, 500ì› ë“±
            r'\d{1,2}\s*ë§Œ\s*ì›',         # 1ë§Œì›, 5ë§Œì› ë“±
            r'\d+\s*ì²œ\s*ì›',             # 1000ì›, 5000ì› ë“±
            r'\d+\s*/\s*kg',              # 1000/kg ë“±
            r'\d+\s*/\s*ê°œ',              # 1000/ê°œ ë“±
        ]
    
    def _load_model(self):
        """TrOCR ëª¨ë¸ ë¡œë“œ"""
        try:
            print("ğŸ”„ TrOCR ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # TrOCR ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì› ë²„ì „)
            model_name = "microsoft/trocr-base-printed"
            self.processor = TrOCRProcessor.from_pretrained(model_name)
            self.model = VisionEncoderDecoderModel.from_pretrained(model_name)
            self.model.to(self.device)
            
            print("âœ… TrOCR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            self.model = None
            self.processor = None
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - ì „í†µì‹œì¥ íŠ¹í™”
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì—´
        """
        # ì´ë¯¸ì§€ ì½ê¸°
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # 2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
        denoised = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # 3. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # 4. ì ì‘ì  ì„ê³„ê°’ ì²˜ë¦¬
        binary = cv2.adaptiveThreshold(
            enhanced, 255, 
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        # 5. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((2, 2), np.uint8)
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # 6. í…ìŠ¤íŠ¸ ì˜ì—­ ê°•ì¡° (ë°˜ì „)
        inverted = cv2.bitwise_not(cleaned)
        
        return inverted
    
    def recognize_text(self, image: np.ndarray) -> str:
        """
        TrOCRì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¸ì‹
        
        Args:
            image: ì´ë¯¸ì§€ ë°°ì—´
            
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸
        """
        if self.model is None or self.processor is None:
            return "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # TrOCR ì²˜ë¦¬
            pixel_values = self.processor(pil_image, return_tensors="pt").pixel_values
            pixel_values = pixel_values.to(self.device)
            
            # í…ìŠ¤íŠ¸ ìƒì„±
            generated_ids = self.model.generate(pixel_values)
            generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
            
            return generated_text.strip()
            
        except Exception as e:
            print(f"TrOCR ì¸ì‹ ì˜¤ë¥˜: {e}")
            return ""
    
    def extract_market_info(self, text: str) -> Dict[str, str]:
        """
        ì „í†µì‹œì¥ ì •ë³´ ì¶”ì¶œ
        
        Args:
            text: ì¸ì‹ëœ í…ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì¡°í™”ëœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            "raw_text": text,
            "product_name": "",
            "price": "",
            "unit": "",
            "origin": "",
            "additional_info": ""
        }
        
        # ê°€ê²© íŒ¨í„´ ë§¤ì¹­
        for pattern in self.price_patterns:
            price_match = re.search(pattern, text)
            if price_match:
                result["price"] = price_match.group(0)
                break
        
        # ìƒí’ˆëª… ì¶”ì¶œ (í‚¤ì›Œë“œ ë§¤ì¹­)
        for keyword in self.market_keywords:
            if keyword in text:
                result["product_name"] = keyword
                break
        
        # ê°€ê²© ì•ë¶€ë¶„ì„ ìƒí’ˆëª…ìœ¼ë¡œ ì¶”ì •
        if result["price"] and not result["product_name"]:
            price_start = text.find(result["price"])
            product_part = text[:price_start].strip()
            result["product_name"] = product_part
        
        # ì›ì‚°ì§€ ì •ë³´ ì¶”ì¶œ
        origin_keywords = ["êµ­ì‚°", "ì œì£¼", "ì œì£¼ë„", "ë¬´ë†ì•½", "ìœ ê¸°ë†", "í•˜ìš°ìŠ¤"]
        for keyword in origin_keywords:
            if keyword in text:
                result["origin"] = keyword
                break
        
        # ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ
        unit_patterns = [r'(\d+)\s*ê°œ', r'(\d+)\s*kg', r'(\d+)\s*ê·¼', r'(\d+)\s*ë´‰', r'(\d+)\s*í¬ê¸°']
        for pattern in unit_patterns:
            unit_match = re.search(pattern, text)
            if unit_match:
                result["unit"] = unit_match.group(0)
                break
        
        return result
    
    def process_image(self, image_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            print(f"ğŸ”„ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {image_path}")
            
            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self.preprocess_image(image_path)
            
            # 2. í…ìŠ¤íŠ¸ ì¸ì‹
            recognized_text = self.recognize_text(processed_image)
            
            if not recognized_text:
                return {
                    "success": False,
                    "error": "í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "engine": "Sibang OCR Prototype"
                }
            
            # 3. ì „í†µì‹œì¥ ì •ë³´ ì¶”ì¶œ
            market_info = self.extract_market_info(recognized_text)
            
            return {
                "success": True,
                "engine": "Sibang OCR Prototype",
                "text": recognized_text,
                "market_info": market_info,
                "confidence": 0.8  # í”„ë¡œí† íƒ€ì…ì´ë¯€ë¡œ ê³ ì •ê°’
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "engine": "Sibang OCR Prototype"
            }

# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def integrate_with_flask():
    """
    Flask ì• í”Œë¦¬ì¼€ì´ì…˜ì— Sibang OCR í†µí•©
    """
    # simple_web_ocr.pyì˜ Sibang OCR ë¶€ë¶„ì„ ì´ í•¨ìˆ˜ë¡œ êµì²´
    pass

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_sibang_ocr():
    """Sibang OCR í”„ë¡œí† íƒ€ì… í…ŒìŠ¤íŠ¸"""
    print("ğŸª Sibang OCR í”„ë¡œí† íƒ€ì… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # í”„ë¡œí† íƒ€ì… ìƒì„±
    ocr = SibangOCRPrototype()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œë“¤
    test_images = [
        "sample_images/test_market_1.jpg",
        "sample_images/test_market_2.jpg", 
        "sample_images/test_market_3.jpg"
    ]
    
    for image_path in test_images:
        if os.path.exists(image_path):
            print(f"\nğŸ“· í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {image_path}")
            result = ocr.process_image(image_path)
            
            if result["success"]:
                print("âœ… OCR ì„±ê³µ!")
                print(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {result['text']}")
                print(f"ğŸª ìƒí’ˆëª…: {result['market_info']['product_name']}")
                print(f"ğŸ’° ê°€ê²©: {result['market_info']['price']}")
                print(f"ğŸ“ ì›ì‚°ì§€: {result['market_info']['origin']}")
            else:
                print(f"âŒ OCR ì‹¤íŒ¨: {result['error']}")
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_sibang_ocr()







