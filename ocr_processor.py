"""
ì‹œì¥ ê°€íŒëŒ€ OCR í”„ë¡œì„¸ì„œ
ì´ë¯¸ì§€ì—ì„œ ìƒí’ˆëª…ê³¼ ê°€ê²©ì„ ì¸ì‹í•˜ì—¬ JSONìœ¼ë¡œ ë³€í™˜
"""

import os
import json
import base64
from typing import Dict, List, Optional, Union
from datetime import datetime
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv("sibangaiocr.env")  # sibangaiocr.env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
from PIL import Image
import cv2
import numpy as np


class MarketOCRProcessor:
    """
    ì‹œì¥ ê°€íŒëŒ€ ìƒí’ˆ ì •ë³´ OCR ì²˜ë¦¬ í´ë˜ìŠ¤
    ì—¬ëŸ¬ OCR ì—”ì§„ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, method: str = "gpt4_vision"):
        """
        ì´ˆê¸°í™” í•¨ìˆ˜
        
        Args:
            method: OCR ë°©ë²• ì„ íƒ
                - "gpt4_vision": OpenAI GPT-4 Vision (ì¶”ì²œ, ê°€ì¥ ì •í™•)
                - "google_vision": Google Cloud Vision API
                - "naver_clova": Naver Clova OCR
                - "pp_ocrv5": PaddleOCR PP-OCRv5 (í•œêµ­ì–´ íŠ¹í™”, ë¡œì»¬ ì‹¤í–‰)
        """
        self.method = method
        self.api_key = None
        self.pp_ocr_ocr = None  # PP-OCRv5 OCR ê°ì²´ (ì§€ì—° ë¡œë”©)
        
        # ì„ íƒí•œ ë°©ë²•ì— ë”°ë¼ API í‚¤ í™•ì¸
        if method == "gpt4_vision":
            self.api_key = os.getenv("OPENAI_API_KEY")
            if not self.api_key:
                raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        elif method == "google_vision":
            self.credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if not self.credentials_path:
                raise ValueError("GOOGLE_APPLICATION_CREDENTIALSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        elif method == "naver_clova":
            self.naver_secret = os.getenv("NAVER_OCR_SECRET_KEY")
            self.naver_url = os.getenv("NAVER_OCR_API_URL")
            if not self.naver_secret or not self.naver_url:
                raise ValueError("Naver Clova OCR ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        elif method == "pp_ocrv5":
            # PP-OCRv5ëŠ” ì§€ì—° ë¡œë”© (ì²˜ìŒ ì‚¬ìš©í•  ë•Œ ëª¨ë¸ ë¡œë“œ)
            # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’ì€ ìë™ ë‹¤ìš´ë¡œë“œ)
            self.pp_ocrv5_model_path = os.getenv("PP_OCRV5_MODEL_PATH", None)
            # í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ ì„¤ì •
            self.pp_ocrv5_use_korean = os.getenv("PP_OCRV5_USE_KOREAN", "True").lower() == "true"
    
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ 
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (numpy array)
        """
        # ì´ë¯¸ì§€ ì½ê¸°
        image = cv2.imread(image_path)
        
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
        denoised = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ëŒ€ë¹„ í–¥ìƒ (CLAHE - Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # ì´ì§„í™” (Adaptive Thresholding)
        binary = cv2.adaptiveThreshold(
            enhanced, 255, 
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        return binary
    
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """
        ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”© (API ì „ì†¡ìš©)
        í•œê¸€ ê²½ë¡œ ë° ì¸ì½”ë”© ë¬¸ì œ ì™„ì „ í•´ê²°
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´
        """
        import tempfile
        import shutil
        
        # í•­ìƒ ì„ì‹œ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        temp_fd = None
        temp_path = None
        
        try:
            # ì•ˆì „í•œ ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_fd, temp_path = tempfile.mkstemp(suffix='.jpg')
            os.close(temp_fd)  # íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì¦‰ì‹œ ë‹«ê¸°
            
            # ì›ë³¸ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ë³µì‚¬
            shutil.copy2(image_path, temp_path)
            
            # ì„ì‹œ íŒŒì¼ì—ì„œ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì½ê¸°
            with open(temp_path, "rb") as temp_file:
                image_data = temp_file.read()
            
            # Base64 ì¸ì½”ë”© (ASCIIë¡œ ì•ˆì „í•˜ê²Œ ë””ì½”ë”©)
            base64_encoded = base64.b64encode(image_data).decode('ascii')
            return base64_encoded
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë” ìì„¸í•œ ì •ë³´ ì œê³µ
            error_msg = f"ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}"
            if temp_path and os.path.exists(temp_path):
                error_msg += f" (ì„ì‹œ íŒŒì¼: {temp_path})"
            raise Exception(error_msg)
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path and os.path.exists(temp_path):
                try:
                    os.unlink(temp_path)
                except:
                    pass
    
    
    def process_with_gpt4_vision(self, image_path: str) -> Dict:
        """
        GPT-4 Vision APIë¥¼ ì‚¬ìš©í•œ OCR ì²˜ë¦¬
        ê°€ì¥ ì •í™•í•˜ê³  ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ë°©ë²•
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ëœ ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        from openai import OpenAI
        
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = OpenAI(api_key=self.api_key)
            
            # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”© (ì•ˆì „í•œ ë°©ì‹)
            base64_image = self.encode_image_to_base64(image_path)
            
            # GPT-4 Visionì—ê²Œ í”„ë¡¬í”„íŠ¸ ì „ì†¡ (ASCII ì „ìš©ìœ¼ë¡œ ë³€ê²½)
            prompt = """
This image shows products and price tags from a market stall.
Please identify all product names and prices from the image and organize them in JSON format.

Output format:
{
  "products": [
    {
      "product_name": "Product name in Korean",
      "price": "Price with won currency",
      "unit": "Unit (e.g., 1 piece, 1 basket, 1kg, etc.)",
      "additional_info": "Additional information if available"
    }
  ]
}

- Recognize Korean handwriting as accurately as possible
- Include won currency unit in the price
- Extract unit information if available
- Recognize all price tags without missing any
"""
            
            # API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",  # ë˜ëŠ” "gpt-4-vision-preview"
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            result_text = response.choices[0].message.content
            
            # JSON íŒŒì‹± (ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]
            
            result = json.loads(result_text.strip())
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result["metadata"] = {
                "method": "gpt4_vision",
                "timestamp": datetime.now().isoformat(),
                "image_path": image_path,
                "total_items": len(result.get("products", []))
            }
            
            return result
            
        except UnicodeDecodeError as e:
            return {
                "error": f"ì¸ì½”ë”© ì˜¤ë¥˜: {str(e)}",
                "message": "íŒŒì¼ ì¸ì½”ë”© ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "solution": "íŒŒì¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            }
        except Exception as e:
            return {
                "error": str(e),
                "message": "GPT-4 Vision ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    
    def process_with_google_vision(self, image_path: str) -> Dict:
        """
        Google Cloud Vision APIë¥¼ ì‚¬ìš©í•œ OCR ì²˜ë¦¬
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ëœ ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        from google.cloud import vision
        
        # Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = vision.ImageAnnotatorClient()
        
        try:
            # ì´ë¯¸ì§€ ì½ê¸°
            with open(image_path, 'rb') as image_file:
                content = image_file.read()
            
            image = vision.Image(content=content)
            
            # í…ìŠ¤íŠ¸ ê°ì§€ ìˆ˜í–‰
            response = client.text_detection(image=image)
            texts = response.text_annotations
            
            if not texts:
                return {
                    "products": [],
                    "message": "í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            full_text = texts[0].description
            
            # í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìƒí’ˆ ì •ë³´ íŒŒì‹±
            products = self._parse_text_to_products(full_text)
            
            result = {
                "products": products,
                "raw_text": full_text,
                "metadata": {
                    "method": "google_vision",
                    "timestamp": datetime.now().isoformat(),
                    "image_path": image_path,
                    "total_items": len(products)
                }
            }
            
            return result
            
        except Exception as e:
            return {
                "error": str(e),
                "message": "Google Vision ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    
    def process_with_naver_clova(self, image_path: str) -> Dict:
        """
        Naver Clova OCRì„ ì‚¬ìš©í•œ ì²˜ë¦¬
        í•œêµ­ì–´ì— íŠ¹í™”ëœ OCR
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ëœ ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        import requests
        
        try:
            # API ìš”ì²­ ì¤€ë¹„
            url = self.naver_url
            headers = {
                'X-OCR-SECRET': self.naver_secret,
                'Content-Type': 'application/json'
            }
            
            # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
            base64_image = self.encode_image_to_base64(image_path)
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ì²˜ë¦¬ (í•œê¸€ ê²½ë¡œ ëŒ€ì‘)
            try:
                file_name = Path(image_path).name
                file_format = Path(image_path).suffix[1:] or 'jpg'
            except:
                file_name = 'image.jpg'
                file_format = 'jpg'
            
            data = {
                'version': 'V2',
                'requestId': f'market_ocr_{datetime.now().timestamp()}',
                'timestamp': int(datetime.now().timestamp() * 1000),
                'images': [
                    {
                        'format': file_format,
                        'name': file_name,
                        'data': base64_image
                    }
                ]
            }
            
            # API í˜¸ì¶œ
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            
            result_data = response.json()
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            full_text = ""
            for image in result_data.get('images', []):
                for field in image.get('fields', []):
                    full_text += field.get('inferText', '') + "\n"
            
            # ìƒí’ˆ ì •ë³´ íŒŒì‹±
            products = self._parse_text_to_products(full_text)
            
            result = {
                "products": products,
                "raw_text": full_text,
                "metadata": {
                    "method": "naver_clova",
                    "timestamp": datetime.now().isoformat(),
                    "image_path": image_path,
                    "total_items": len(products)
                }
            }
            
            return result
            
        except Exception as e:
            return {
                "error": str(e),
                "message": "Naver Clova OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    def process_with_naver_clova_from_data(self, image_data: bytes) -> Dict:
        """
        Naver Clova OCRì„ ì‚¬ìš©í•œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ë°ì´í„° ì§ì ‘ ì „ë‹¬)
        í•œêµ­ì–´ì— íŠ¹í™”ëœ OCR
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        import requests
        
        try:
            # API ìš”ì²­ ì¤€ë¹„
            url = self.naver_url
            headers = {
                'X-OCR-SECRET': self.naver_secret,
                'Content-Type': 'application/json'
            }
            
            # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
            import base64
            base64_image = base64.b64encode(image_data).decode('ascii')
            
            # API ìš”ì²­ ë°ì´í„°
            data = {
                "version": "V2",
                "requestId": "ocr_request",
                "timestamp": int(datetime.now().timestamp() * 1000),
                "images": [
                    {
                        "name": "image",
                        "format": "jpg",
                        "data": base64_image
                    }
                ]
            }
            
            # API í˜¸ì¶œ
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            
            # ì‘ë‹µ ì²˜ë¦¬
            result = response.json()
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = ""
            if 'images' in result and len(result['images']) > 0:
                fields = result['images'][0].get('fields', [])
                for field in fields:
                    if 'inferText' in field:
                        extracted_text += field['inferText'] + " "
            
            return {
                "text": extracted_text.strip(),
                "raw_result": result
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "text": ""
            }
    
    
    def _load_pp_ocrv5_model(self):
        """
        PP-OCRv5 ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)
        ì²˜ìŒ ì‚¬ìš©í•  ë•Œë§Œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
        """
        if self.pp_ocr_ocr is None:
            try:
                from paddleocr import PaddleOCR
                import paddle
                
                # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                gpu_available = False
                gpu_device = "CPU"
                try:
                    # PaddlePaddleì´ CUDAë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
                    if paddle.device.is_compiled_with_cuda():
                        # GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
                        if paddle.device.cuda.device_count() > 0:
                            gpu_available = True
                            gpu_device = f"GPU (CUDA {paddle.device.cuda.device_count()}ê°œ)"
                            print(f"ğŸš€ GPU ê°ì§€ë¨: {gpu_device}")
                        else:
                            print("âš ï¸ CUDAëŠ” ì§€ì›ë˜ì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ GPUê°€ ì—†ìŠµë‹ˆë‹¤. CPU ì‚¬ìš©.")
                    else:
                        print("â„¹ï¸ CUDAê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¹Œë“œì…ë‹ˆë‹¤. CPU ì‚¬ìš©.")
                except Exception as e:
                    print(f"âš ï¸ GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}. CPU ì‚¬ìš©.")
                
                # í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì„¤ì •
                if self.pp_ocrv5_use_korean:
                    # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©
                    # lang='korean': í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš© (korean_PP-OCRv5_mobile_rec)
                    # use_doc_orientation_classify: ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜ ì‚¬ìš© (ì„±ëŠ¥ í–¥ìƒ)
                    # use_textline_orientation: í…ìŠ¤íŠ¸ ë¼ì¸ ë°©í–¥ ê°ì§€ ì‚¬ìš© (ì„±ëŠ¥ í–¥ìƒ)
                    # text_rec_score_thresh: í…ìŠ¤íŠ¸ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ í…ìŠ¤íŠ¸ ì¸ì‹)
                    self.pp_ocr_ocr = PaddleOCR(
                        lang='korean',  # í•œêµ­ì–´ ëª¨ë¸
                        use_doc_orientation_classify=True,  # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜ í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
                        use_textline_orientation=True,  # í…ìŠ¤íŠ¸ ë¼ì¸ ë°©í–¥ ê°ì§€ í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
                        text_rec_score_thresh=0.5,  # í…ìŠ¤íŠ¸ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.5 = 50% ì´ìƒ)
                        ocr_version='PP-OCRv5'  # PP-OCRv5 ë²„ì „ ëª…ì‹œ
                    )
                else:
                    # ê¸°ë³¸ ë‹¤êµ­ì–´ ëª¨ë¸ ì‚¬ìš©
                    self.pp_ocr_ocr = PaddleOCR(
                        lang='ch',  # ì¤‘êµ­ì–´/ì˜ì–´ ê¸°ë³¸ ëª¨ë¸ (í•œêµ­ì–´ë„ ì§€ì›)
                        use_doc_orientation_classify=True,
                        use_textline_orientation=True,
                        text_rec_score_thresh=0.5,
                        ocr_version='PP-OCRv5'
                    )
                
                # GPU ì‚¬ìš© ì •ë³´ ì €ì¥ (ê²°ê³¼ì— í¬í•¨í•˜ê¸° ìœ„í•´)
                self.pp_ocr_gpu_info = {
                    "gpu_available": gpu_available,
                    "gpu_device": gpu_device,
                    "using_gpu": gpu_available  # PaddleOCRì€ ìë™ìœ¼ë¡œ GPU ì‚¬ìš©
                }
                
                print(f"âœ… PP-OCRv5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({gpu_device})")
                
            except ImportError:
                raise ImportError(
                    "PaddleOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                    "ì„¤ì¹˜í•˜ë ¤ë©´: pip install paddleocr paddlepaddle"
                )
            except Exception as e:
                raise Exception(f"PP-OCRv5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        return self.pp_ocr_ocr
    
    
    def process_with_pp_ocrv5(self, image_path: str) -> Dict:
        """
        PP-OCRv5 ëª¨ë¸ì„ ì‚¬ìš©í•œ OCR ì²˜ë¦¬
        í•œêµ­ì–´ì— íŠ¹í™”ëœ PaddleOCRì˜ ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ëœ ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # PP-OCRv5 ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)
            ocr = self._load_pp_ocrv5_model()
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸° (í•œê¸€ ê²½ë¡œ ëŒ€ì‘)
            # PaddleOCRì€ íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ë°›ì„ ìˆ˜ ìˆì§€ë§Œ, 
            # í•œê¸€ ê²½ë¡œ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ numpy arrayë¡œ ë³€í™˜
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            # OCR ìˆ˜í–‰
            # PaddleOCR 3.3.2ì—ì„œëŠ” result[0]ì´ OCRResult ê°ì²´
            result = ocr.ocr(image)
            
            # ê²°ê³¼ íŒŒì‹±
            full_text = ""
            text_lines = []
            
            if result and len(result) > 0:
                ocr_result = result[0]
                
                # OCRResult ê°ì²´ëŠ” ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ ë™ì‘
                # rec_texts: ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
                # rec_scores: ê° í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸
                # get() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                texts = ocr_result.get('rec_texts', []) or []
                scores = ocr_result.get('rec_scores', []) or []
                
                # í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ë¥¼ ë§¤ì¹­
                if texts:
                    for i, text in enumerate(texts):
                        if text and isinstance(text, str):
                            confidence = scores[i] if i < len(scores) else 0.0
                            full_text += text + "\n"
                            text_lines.append({
                                "text": text,
                                "confidence": float(confidence)
                            })
            
            # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜
            if not full_text.strip():
                return {
                    "products": [],
                    "raw_text": "",
                    "error": "í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "message": "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ìƒí’ˆ ì •ë³´ íŒŒì‹±
            products = self._parse_text_to_products(full_text)
            
            # GPU ì‚¬ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
            gpu_info = getattr(self, 'pp_ocr_gpu_info', {
                "gpu_available": False,
                "gpu_device": "CPU",
                "using_gpu": False
            })
            
            # ê²°ê³¼ êµ¬ì„±
            result_dict = {
                "products": products,
                "raw_text": full_text.strip(),
                "text_lines": text_lines,  # ê° ë¼ì¸ë³„ ìƒì„¸ ì •ë³´
                "metadata": {
                    "method": "pp_ocrv5",
                    "timestamp": datetime.now().isoformat(),
                    "image_path": image_path,
                    "total_items": len(products),
                    "total_text_lines": len(text_lines),
                    "korean_model": self.pp_ocrv5_use_korean,
                    "gpu_info": gpu_info  # GPU ì‚¬ìš© ì •ë³´ ì¶”ê°€
                }
            }
            
            return result_dict
            
        except ImportError as e:
            return {
                "error": f"PaddleOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "message": "PaddleOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install paddleocr paddlepaddleë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."
            }
        except Exception as e:
            return {
                "error": str(e),
                "message": "PP-OCRv5 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    
    def _parse_text_to_products(self, text: str) -> List[Dict]:
        """
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆëª…ê³¼ ê°€ê²© íŒŒì‹±
        ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ íŒŒì‹± (ê°œì„  ê°€ëŠ¥)
        
        Args:
            text: OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            
        Returns:
            ìƒí’ˆ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        import re
        
        products = []
        lines = text.strip().split('\n')
        
        # ê°€ê²© íŒ¨í„´ (ì˜ˆ: 800ì›, 5000ì›, 10,000ì›, 1ë§Œì›)
        price_pattern = r'(\d[\d,]*)\s*ì›|(\d+)\s*ë§Œ\s*ì›'
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # ê°€ê²©ì„ ì°¾ìŒ
            price_match = re.search(price_pattern, line)
            if price_match:
                # ê°€ê²©ì´ ìˆëŠ” ê²½ìš°, ì´ì „ ë¼ì¸ì´ë‚˜ ê°™ì€ ë¼ì¸ì—ì„œ ìƒí’ˆëª… ì°¾ê¸°
                product_name = ""
                price = price_match.group(0)
                
                # ê°€ê²© ì•ë¶€ë¶„ì„ ìƒí’ˆëª…ìœ¼ë¡œ ì¶”ì •
                product_name = line[:price_match.start()].strip()
                
                # ìƒí’ˆëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ì „ ë¼ì¸ í™•ì¸
                if not product_name and i > 0:
                    product_name = lines[i-1].strip()
                
                if product_name:
                    products.append({
                        "product_name": product_name,
                        "price": price,
                        "unit": "",
                        "confidence": 0.7
                    })
        
        return products
    
    
    def process_image(self, image_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        ì„¤ì •ëœ ë°©ë²•ìœ¼ë¡œ OCR ìˆ˜í–‰
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¸ì‹ëœ ìƒí’ˆ ì •ë³´ (JSON í˜•íƒœ)
        """
        # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(image_path):
            return {
                "error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "image_path": image_path
            }
        
        # ì„ íƒí•œ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬
        if self.method == "gpt4_vision":
            return self.process_with_gpt4_vision(image_path)
        elif self.method == "google_vision":
            return self.process_with_google_vision(image_path)
        elif self.method == "naver_clova":
            return self.process_with_naver_clova(image_path)
        elif self.method == "pp_ocrv5":
            return self.process_with_pp_ocrv5(image_path)
        else:
            return {
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” OCR ë°©ë²•: {self.method}",
                "supported_methods": ["gpt4_vision", "google_vision", "naver_clova", "pp_ocrv5"]
            }
    
    
    def save_result(self, result: Dict, output_path: str = "result.json"):
        """
        ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            result: ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ… ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")


# ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ì§ì ‘ ì‹¤í–‰í•  ë•Œ
if __name__ == "__main__":
    import argparse
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="ì‹œì¥ ê°€íŒëŒ€ ìƒí’ˆ OCR")
    parser.add_argument("--image", "-i", required=True, help="ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument(
        "--method", "-m", 
        default="gpt4_vision",
        choices=["gpt4_vision", "google_vision", "naver_clova", "pp_ocrv5"],
        help="OCR ë°©ë²• ì„ íƒ (gpt4_vision, google_vision, naver_clova, pp_ocrv5)"
    )
    parser.add_argument("--output", "-o", default="result.json", help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    # í”„ë¡œì„¸ì„œ ìƒì„± ë° ì‹¤í–‰
    print(f"ğŸš€ OCR ì²˜ë¦¬ ì‹œì‘... (ë°©ë²•: {args.method})")
    print(f"ğŸ“· ì´ë¯¸ì§€: {args.image}")
    
    processor = MarketOCRProcessor(method=args.method)
    result = processor.process_image(args.image)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“Š ì¸ì‹ ê²°ê³¼")
    print("="*50)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # ê²°ê³¼ ì €ì¥
    processor.save_result(result, args.output)

